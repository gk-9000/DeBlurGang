{"cells":[{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":22,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-09T23:33:53.311658Z","iopub.status.busy":"2024-04-09T23:33:53.311302Z","iopub.status.idle":"2024-04-09T23:33:59.814397Z","shell.execute_reply":"2024-04-09T23:33:59.813457Z","shell.execute_reply.started":"2024-04-09T23:33:53.311629Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.autograd as autograd\n","import torchvision.models as models\n","from torch.autograd import Variable\n","\n","\n","###############################################################################\n","# Functions\n","###############################################################################\n","\n","class PerceptualLoss():\n","    def initialize(self, loss):\n","        self.criterion = loss\n","        self.contentFunc = self.contentFunc()\n","\n","    def contentFunc(self):\n","        # Load vgg19 model\n","        conv_3_3_layer = 14\n","        cnn = models.vgg19(pretrained=True).features\n","        cnn = cnn.cuda()\n","        model = nn.Sequential()\n","        model = model.cuda()\n","        for i, layer in enumerate(list(cnn)):\n","            model.add_module(str(i), layer)\n","            if i == conv_3_3_layer:\n","                break\n","        return model\n","\n","    def get_loss(self, fakeIm, realIm):\n","        f_fake = self.contentFunc.forward(fakeIm)\n","        f_real = self.contentFunc.forward(realIm)\n","        f_real_no_grad = f_real.detach()\n","        loss = self.criterion(f_fake, f_real_no_grad)\n","        return loss\n","\n","\n","class GANLoss(nn.Module):\n","    def __init__(self, use_l1=True, target_real_label=1.0, target_fake_label=0.0,\n","                 tensor=torch.FloatTensor):\n","        super(GANLoss, self).__init__()\n","        self.real_label = target_real_label\n","        self.fake_label = target_fake_label\n","        self.real_label_var = None\n","        self.fake_label_var = None\n","        self.Tensor = tensor\n","        if use_l1:\n","            self.loss = nn.L1Loss()\n","        else:\n","            self.loss = nn.BCELoss()\n","\n","    def get_target_tensor(self, input, target_is_real):\n","        target_tensor = None\n","        if target_is_real:\n","            create_label = ((self.real_label_var is None) or\n","                            (self.real_label_var.numel() != input.numel()))\n","            if create_label:\n","                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n","                self.real_label_var = Variable(real_tensor, requires_grad=False)\n","            target_tensor = self.real_label_var\n","        else:\n","            create_label = ((self.fake_label_var is None) or\n","                            (self.fake_label_var.numel() != input.numel()))\n","            if create_label:\n","                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n","                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n","            target_tensor = self.fake_label_var\n","        return target_tensor\n","\n","    def __call__(self, input, target_is_real):\n","        target_tensor = self.get_target_tensor(input, target_is_real)\n","        return self.loss(input, target_tensor)\n","\n","\n","class DiscLoss():\n","    def name(self):\n","        return 'DiscLoss'\n","\n","    def initialize(self, tensor):\n","        self.criterionGAN = GANLoss(use_l1=False, tensor=tensor)\n","\n","    def get_g_loss(self, net, realA, fakeB):\n","        # First, G(A) should fake the discriminator\n","        pred_fake = net.forward(fakeB)\n","        return self.criterionGAN(pred_fake, 1)\n","\n","    def get_loss(self, net, realA, fakeB, realB):\n","        # Fake\n","        # stop backprop to the generator by detaching fake_B\n","        # Generated Image Disc Output should be close to zero\n","        self.pred_fake = net.forward(fakeB.detach())\n","        self.loss_D_fake = self.criterionGAN(self.pred_fake, 0)\n","\n","        # Real\n","        self.pred_real = net.forward(realB)\n","        self.loss_D_real = self.criterionGAN(self.pred_real, 1)\n","\n","        # Combined loss\n","        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n","        return self.loss_D\n","\n","\n","class DiscLossLS(DiscLoss):\n","    def name(self):\n","        return 'DiscLossLS'\n","\n","    def initialize(self, tensor):\n","        DiscLoss.initialize(self, tensor)\n","        self.criterionGAN = GANLoss(use_l1=True, tensor=tensor)\n","\n","    def get_g_loss(self, net, realA, fakeB):\n","        return DiscLoss.get_g_loss(self, net, realA, fakeB)\n","\n","    def get_loss(self, net, realA, fakeB, realB):\n","        return DiscLoss.get_loss(self, net, realA, fakeB, realB)\n","\n","\n","class DiscLossWGANGP(DiscLossLS):\n","    def name(self):\n","        return 'DiscLossWGAN-GP'\n","\n","    def initialize(self, tensor):\n","        DiscLossLS.initialize(self, tensor)\n","        self.LAMBDA = 10\n","\n","    def get_g_loss(self, net, realA, fakeB):\n","        # First, G(A) should fake the discriminator\n","        self.D_fake = net.forward(fakeB)\n","        return -self.D_fake.mean()\n","\n","    def calc_gradient_penalty(self, netD, real_data, fake_data):\n","        alpha = torch.rand(1, 1)\n","        alpha = alpha.expand(real_data.size())\n","        alpha = alpha.cuda()\n","\n","        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n","\n","        interpolates = interpolates.cuda()\n","        interpolates = Variable(interpolates, requires_grad=True)\n","\n","        disc_interpolates = netD.forward(interpolates)\n","\n","        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n","                                  grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n","                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n","\n","        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * self.LAMBDA\n","        return gradient_penalty\n","\n","    def get_loss(self, net, realA, fakeB, realB):\n","        self.D_fake = net.forward(fakeB.detach())\n","        self.D_fake = self.D_fake.mean()\n","\n","        self.D_real = net.forward(realB)\n","        self.D_real = self.D_real.mean()\n","        \n","        self.loss_D = self.D_fake - self.D_real\n","        gradient_penalty = self.calc_gradient_penalty(net, realB.data, fakeB.data)\n","        return self.loss_D + gradient_penalty\n","\n","\n","def init_loss(tensor):\n","    disc_loss = None\n","    content_loss = None\n","\n","    content_loss = PerceptualLoss()\n","    content_loss.initialize(nn.MSELoss())\n","\n","    disc_loss = DiscLoss()\n","\n","    disc_loss.initialize(tensor)\n","    return disc_loss, content_loss\n","\n","def get_loss(tensor, netD, realA, fakeB, realB):\n","    gan_loss, constant_loss = init_loss(tensor)\n","    loss_D = gan_loss.get_loss(netD, realA, fakeB, realB)\n","    loss_G = gan_loss.get_g_loss(netD, realA, fakeB) + constant_loss.get_loss(fakeB, realB)\n","    return loss_D, loss_G"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T23:33:59.817346Z","iopub.status.busy":"2024-04-09T23:33:59.816431Z","iopub.status.idle":"2024-04-09T23:33:59.831016Z","shell.execute_reply":"2024-04-09T23:33:59.82994Z","shell.execute_reply.started":"2024-04-09T23:33:59.817306Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import numpy as np\n","from math import exp\n","import math\n","\n","\n","def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size / 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n","    return gauss / gauss.sum()\n","\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size))\n","    return window\n","\n","\n","def SSIM(img1, img2):\n","    (_, channel, _, _) = img1.size()\n","    window_size = 11\n","    window = create_window(window_size, channel)\n","    mu1 = F.conv2d(img1, window, padding=window_size / 2, groups=channel)\n","    mu2 = F.conv2d(img2, window, padding=window_size / 2, groups=channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1 * mu2\n","\n","    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size / 2, groups=channel) - mu1_sq\n","    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size / 2, groups=channel) - mu2_sq\n","    sigma12 = F.conv2d(img1 * img2, window, padding=window_size / 2, groups=channel) - mu1_mu2\n","\n","    c1 = 0.01 ** 2\n","    c2 = 0.03 ** 2\n","\n","    ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))\n","    return ssim_map.mean()\n","\n","\n","def PSNR(img1, img2):\n","    mse = np.mean((img1 / 255. - img2 / 255.) ** 2)\n","    if mse == 0:\n","        return 100\n","    PIXEL_MAX = 1\n","    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T02:05:38.368451Z","iopub.status.busy":"2024-04-10T02:05:38.367758Z","iopub.status.idle":"2024-04-10T02:05:38.39753Z","shell.execute_reply":"2024-04-10T02:05:38.396532Z","shell.execute_reply.started":"2024-04-10T02:05:38.368417Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import transforms as tfs\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from PIL import Image\n","import random\n","import math\n","        \n","class ReadConcat(Dataset):\n","    def __init__(self, opt):\n","        img_list = []\n","        for folder in os.listdir(os.path.join(opt.dataroot, 'downscaled_images/downscaled_images')):\n","            i = 0\n","            if not os.path.isdir(os.path.join(opt.dataroot, 'downscaled_images/downscaled_images', folder)):\n","                continue\n","            for file in os.listdir(os.path.join(opt.dataroot, 'downscaled_images/downscaled_images', folder)):\n","                if file.endswith('.png'):\n","                    if i == 10:\n","                        break\n","                    img_list.append(os.path.join(folder, file))\n","                    i += 1\n","        \n","        self.img_pathsA = [os.path.join(opt.dataroot,'Set B/Set B', 'type3', k) for k in img_list]\n","        self.img_pathsB = [os.path.join(opt.dataroot,'downscaled_images/downscaled_images', k) for k in img_list]\n","        self.img_name = img_list\n","        self.opt = opt\n","        transform_list = [tfs.ToTensor(),\n","                          tfs.Normalize((0.5, 0.5, 0.5),\n","                                               (0.5, 0.5, 0.5))]\n","\n","        self.transform = tfs.Compose(transform_list)\n","\n","    def __getitem__(self, index):\n","        img_name = self.img_name[index]\n","        # img = Image.open(self.img_paths[index]).convert('RGB')\n","        imgA = Image.open(self.img_pathsA[index]).convert('RGB')\n","        imgB = Image.open(self.img_pathsB[index]).convert('RGB')\n","        A = imgA.resize((self.opt.loadSizeX, self.opt.loadSizeY), Image.BICUBIC)\n","        B = imgB.resize((self.opt.loadSizeX, self.opt.loadSizeY), Image.BICUBIC)\n","        A = self.transform(A)\n","        B = self.transform(B)\n","\n","        if (not self.opt.no_flip) and random.random() < 0.5:\n","            idx = [i for i in range(A.size(2) - 1, -1, -1)]\n","            idx = torch.LongTensor(idx)\n","            A = A.index_select(2, idx)\n","            B = B.index_select(2, idx)\n","\n","\n","        return {'A': A, 'B': B, 'img_name': img_name}\n","\n","    def __len__(self):\n","\n","        return len(self.img_pathsA)\n","\n","##################################################################################\n","\n","####################################ImageProcessing##############################\n","\n","\n","def image_transform(x):\n","    transform_list = []\n","    transform_list += [tfs.ToTensor(),\n","                       tfs.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n","    transform = tfs.Compose(transform_list)\n","    return transform(x)    \n","\n","\n","def image_recovery(image_tensor, imtype=np.uint8):\n","    image_numpy = image_tensor[0].cpu().float().detach().numpy()\n","    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n","    return image_numpy.astype(imtype)\n","\n","    \n","    \n","def show_compareImage(seta, setb):\n","    dataset_num = len(seta)\n","    idxs = np.random.choice(dataset_num, 4, replace=False)\n","    plt.figure(figsize=(14, 6))\n","    for i in range(1, 5):\n","        plt.subplot(2, 4, i)\n","        plt.imshow(seta[idxs[i-1]])\n","    for i in range(5, 9):\n","        plt.subplot(2, 4, i)\n","        plt.imshow(setb[idxs[i-5]])\n","    plt.pause(0)\n","\n","\n","def save_image(image_numpy, image_path):\n","    if image_numpy.shape[2] == 1:\n","        image_numpy = np.reshape(image_numpy, (image_numpy.shape[0],image_numpy.shape[1]))\n","        image_pil = Image.fromarray(image_numpy, 'L')\n","    else:\n","        image_pil = Image.fromarray(image_numpy)\n","    image_pil.save(image_path)\n","#####################################################################################\n","\n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","        \n","    elif classname.find('BatchNorm2d') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","\n","\n","def update_lr(optim, lr, niter_decay):\n","    old_lr = lr\n","    lrd = lr / niter_decay\n","    lr -= lrd\n","    for param_group in optim.param_groups:\n","        param_group['lr'] = lr\n","    print('update learning rate: %f -> %f' % (old_lr, lr))\n","    return lr\n","\n","\n","def save_net(net, checkpoints_dir, net_name, epoch_label):\n","    save_filename = '%s_net_%s.pth' % (epoch_label, net_name)\n","    check_folder(checkpoints_dir)\n","    save_path = os.path.join(checkpoints_dir, save_filename)\n","    torch.save(net.cpu().state_dict(), save_path)\n","    if torch.cuda.is_available():\n","        net.cuda()\n","    print('save_net{}: {}'.format(net_name, save_filename))\n","\n","\n","def load_net(net, checkpoints_dir, net_name, epoch_label):\n","    save_filename = '%s_net_%s.pth' % (epoch_label, net_name)\n","    save_path = os.path.join(checkpoints_dir, save_filename)\n","    net.load_state_dict(torch.load(save_path))\n","    print('load_net{}: {}'.format(net_name, save_filename))\n","    \n","    \n","def check_folder(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","    "]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T23:33:59.867243Z","iopub.status.busy":"2024-04-09T23:33:59.866921Z","iopub.status.idle":"2024-04-09T23:33:59.889299Z","shell.execute_reply":"2024-04-09T23:33:59.888234Z","shell.execute_reply.started":"2024-04-09T23:33:59.867221Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","# import numpy as np\n","\n","##########################################Generator##############################################\n","\n","class DeblurGenerator(nn.Module):\n","    def __init__(self, padding_type='reflect'):\n","        super(DeblurGenerator, self).__init__()\n","        # conv-->(downsamping x 2)-->(resnblock x 9)-->(deconv x 2)-->conv-->\n","        deblur_model = [\n","            nn.ReflectionPad2d(3),\n","            nn.Conv2d(3, 64, 7, padding=0),\n","            nn.InstanceNorm2d(64, track_running_stats=True),\n","            nn.ReLU(True)\n","        ]\n","\n","        deblur_model += [\n","            nn.Conv2d(64, 128, 3, 2, padding=1),\n","            nn.InstanceNorm2d(128, track_running_stats=True),\n","            nn.ReLU(True),\n","            nn.Conv2d(128, 256, 3, 2, padding=1),\n","            nn.InstanceNorm2d(256, track_running_stats=True),\n","            nn.ReLU(True)\n","        ]\n","\n","        for i in range(9):\n","            deblur_model += [\n","                Resblock(256, padding_type)\n","            ]\n","\n","        deblur_model += [\n","            nn.ConvTranspose2d(256, 128, 3, 2, padding=1, output_padding=1),\n","            nn.InstanceNorm2d(128, track_running_stats=True),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(128, 64, 3, 2, padding=1, output_padding=1),\n","            nn.InstanceNorm2d(64, track_running_stats=True),\n","            nn.ReLU(True),\n","        ]\n","\n","        deblur_model += [\n","            nn.ReflectionPad2d(3),\n","            nn.Conv2d(64, 3, 7, padding=0),\n","            nn.Tanh()\n","        ]\n","\n","        self.model = nn.Sequential(*deblur_model)\n","\n","    def forward(self, x):\n","        res = x\n","        out = self.model(x)\n","        return torch.clamp(out + res, min=-1, max=1)\n","\n","\n","class Resblock(nn.Module):\n","    def __init__(self, channel, padding_type):\n","        super(Resblock, self).__init__()\n","        # conv-->instanceNorm-->relu-->conv-->instanceNorm-->\n","        self.conv_block = self.build_conv_block(channel, padding_type)\n","\n","    def build_conv_block(self, channel, padding_type):\n","        conv_block = []\n","\n","        if padding_type == 'reflect':\n","            conv_block += [nn.ReflectionPad2d(1)]\n","        elif padding_type == 'replicate':\n","            conv_block += [nn.ReplicationPad2d(1)]\n","        elif padding_type == 'zero':\n","            conv_block += [nn.ZeroPad2d(1)]\n","        else:\n","            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","\n","        conv_block += [nn.Conv2d(channel, channel, kernel_size=3, padding=0),\n","                       nn.InstanceNorm2d(channel),\n","                       nn.ReLU(True)]\n","\n","        conv_block += [nn.Dropout(0.5)]\n","\n","        return nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        conv_block = self.conv_block(x)\n","        return conv_block + x\n","\n","\n","###########################################################################################\n","\n","####################################Discriminator##########################################\n","\n","\n","class DeblurDiscriminator(nn.Module):\n","    def __init__(self):\n","        super(DeblurDiscriminator, self).__init__()\n","        # conv-->(downsampling x 2)-->conv-->conv-->\n","        dis_model = [\n","            nn.Conv2d(3, 64, 4, 2, padding=2),\n","            nn.InstanceNorm2d(64),\n","            nn.LeakyReLU(0.2, True)\n","        ]\n","\n","        dis_model += [\n","            nn.Conv2d(64, 128, 4, 2, padding=2),\n","            nn.InstanceNorm2d(128),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Conv2d(128, 256, 4, 2, padding=2),\n","            nn.InstanceNorm2d(256),\n","            nn.LeakyReLU(0.2, True),\n","        ]\n","\n","        dis_model += [\n","            nn.Conv2d(256, 512, 4, 1, padding=2),\n","            nn.InstanceNorm2d(512),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Conv2d(512, 1, 4, 1, padding=2),\n","            nn.Sigmoid()\n","        ]\n","\n","        self.model = nn.Sequential(*dis_model)\n","\n","    def forward(self, x):\n","        out = self.model(x)\n","\n","        return out\n","\n","################################################################################\n","\n","#####################################test model#################################\n","# testnet = DeblurGenerator()\n","# test_x = Variable(torch.zeros(1,3, 72,72))\n","# print('################test G ####################')\n","# print('G_input: {}'.format(test_x.shape))\n","# test_y= testnet(test_x)\n","# print('G_output: {}'.format(test_y.shape))\n","#\n","#\n","# testnet = DeblurDiscriminator()\n","# test_x = Variable(torch.zeros(1,3, 72,72))\n","# print('################test D#####################')\n","# print('D_input: {}'.format(test_x.shape))\n","# test_y= testnet.forward(test_x) # 与testnet(test_x)一样\n","# print('D_output: {}'.format(test_y.shape))\n","\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T23:33:59.891079Z","iopub.status.busy":"2024-04-09T23:33:59.890698Z","iopub.status.idle":"2024-04-09T23:33:59.908712Z","shell.execute_reply":"2024-04-09T23:33:59.908002Z","shell.execute_reply.started":"2024-04-09T23:33:59.891047Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","# import matplotlib.pyplot as plt\n","# from utils import ReadConcat, image_recovery, update_lr, check_folder, save_image, save_net\n","# from losses import get_loss\n","from torch.utils.data import DataLoader\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","def set_requires_grad(nets, requires_grad=False):\n","    \"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n","    Parameters:\n","        nets (network list)   -- a list of networks\n","        requires_grad (bool)  -- whether the networks require gradients or not\n","    \"\"\"\n","    if not isinstance(nets, list):\n","        nets = [nets]\n","    for net in nets:\n","        if net is not None:\n","            for param in net.parameters():\n","                param.requires_grad = requires_grad\n","\n","def train(opt, netG, netD, optim_G, optim_D):\n","    tensor = torch.cuda.FloatTensor\n","    # lossD_list = []\n","    # lossG_list = []\n","\n","    train = ReadConcat(opt)\n","    trainset = DataLoader(train, batch_size=opt.batchSize, shuffle=True)\n","    save_img_path = os.path.join('./result', 'train')\n","    check_folder(save_img_path)\n","\n","    for e in range(opt.epoch, opt.niter + opt.niter_decay + 1):\n","        for i, data in enumerate(trainset):\n","            # set input\n","            data_A = data['A'] # blur\n","            data_B = data['B'] #sharp\n","            # plt.imshow(image_recovery(data_A.squeeze().numpy()))\n","            # plt.pause(0)\n","            # print(data_A.shape)\n","            # print(data_B.shape)\n","\n","            if torch.cuda.is_available():\n","                data_A = data_A.cuda(opt.gpu)\n","                data_B = data_B.cuda(opt.gpu)\n","            # forward\n","            realA = Variable(data_A)\n","            fakeB = netG(realA)\n","            realB = Variable(data_B)\n","\n","            # optimize_parameters\n","            # optimizer netD\n","            set_requires_grad([netD], True)\n","            for iter_d in range(1):\n","                optim_D.zero_grad()\n","                loss_D, _ = get_loss(tensor, netD, realA, fakeB, realB)\n","                loss_D.backward()\n","                optim_D.step()\n","\n","            # optimizer netG\n","            set_requires_grad([netD], False)\n","            optim_G.zero_grad()\n","            _, loss_G = get_loss(tensor, netD, realA, fakeB, realB)\n","            loss_G.backward()\n","            optim_G.step()\n","            if i % 50 == 0:\n","                # lossD_list.append(loss_D)\n","                # lossG_list.append(loss_G)\n","                print('{}/{}: lossD:{}, lossG:{}'.format(i, e, loss_D, loss_G))\n","\n","        visul_img = torch.cat((realA, fakeB, realA), 3)\n","        #print(type(visul_img), visul_img.size())\n","        visul_img = image_recovery(visul_img)\n","        #print(visul_img.size)\n","        save_image(visul_img, os.path.join(save_img_path,'epoch'+str(e)+'.png'))\n","\n","        if e > opt.niter:\n","            update_lr(optim_D, opt.lr, opt.niter_decay)\n","            lr = (optim_G, opt.lr, opt.niter_decay)\n","            opt.lr = lr\n","\n","        if e % opt.save_epoch_freq == 0:\n","            save_net(netG, opt.checkpoints_dir, 'G', e)\n","            save_net(netD, opt.checkpoints_dir, 'D', e)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T23:33:59.910327Z","iopub.status.busy":"2024-04-09T23:33:59.909675Z","iopub.status.idle":"2024-04-09T23:33:59.923776Z","shell.execute_reply":"2024-04-09T23:33:59.923007Z","shell.execute_reply.started":"2024-04-09T23:33:59.910294Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","# from utils import ReadConcat, check_folder, image_transform, image_recovery, save_image, PSNR\n","import os\n","\n","\n","def test(opt, netG):\n","    aver_psnr = 0.0\n","    #aver_ssim = 0.0\n","    counter = 0\n","\n","    test = ReadConcat(opt)\n","    testset = DataLoader(test, batch_size=1, shuffle=False)\n","    save_path = os.path.join(opt.out_dir, 'test')\n","    os.makedirs(save_path, exist_ok=True)\n","    check_folder(save_path)\n","    netG.eval()\n","    \n","    res = 0\n","    for i,data in enumerate(testset):\n","        if (res == 99):\n","            break\n","        counter = i\n","        data_A = data['A']  # blur\n","        data_B = data['B']  # sharp\n","        if torch.cuda.is_available():\n","            data_A = data_A.cuda(opt.gpu)\n","            data_B = data_B.cuda(opt.gpu)\n","        with torch.no_grad():\n","            realA = Variable(data_A)\n","            realB = Variable(data_B)\n","\n","        fakeB = netG(realA)\n","        # fakeB = image_recovery(fakeB.squeeze().cpu().detach().numpy())\n","        # realB = image_recovery(realB.squeeze().cpu().detach().numpy())\n","        fakeB = image_recovery(fakeB)\n","        realB = image_recovery(realB)\n","\n","        aver_psnr += PSNR(fakeB, realB)\n","        # fakeB = Image.fromarray(fakeB)\n","        # realB = Image.fromarray(realB)\n","        # aver_ssim += SSIM(fakeB, realB)\n","        res += 1 \n","        # save image\n","        img_path = data['img_name']\n","        save_image(fakeB, os.path.join(save_path, img_path[0]))\n","        print('save successfully {}'.format(save_path))\n","\n","    aver_psnr /= counter\n","    # aver_ssim /= counter\n","    print('PSNR = %f' % (aver_psnr))"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T23:33:59.925273Z","iopub.status.busy":"2024-04-09T23:33:59.924965Z","iopub.status.idle":"2024-04-09T23:33:59.938652Z","shell.execute_reply":"2024-04-09T23:33:59.937827Z","shell.execute_reply.started":"2024-04-09T23:33:59.925238Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["6067459\n","2764737\n"]}],"source":["import argparse\n","# from model import DeblurGenerator, DeblurDiscriminator\n","# from train import train\n","# from test import test\n","# from utils import weights_init, load_net\n","import torch\n","\n","# parser = argparse.ArgumentParser()\n","\n","# parser.add_argument('--model', type=str, default='train', help='train or test')\n","# parser.add_argument('--dataroot', default='./data/dataset/concat_AB', help='path to dataset')\n","# parser.add_argument('--out_dir', default='./result', help='output direction')\n","# parser.add_argument('--loadSizeX', type=int, default=360, help='scale images to this size')\n","# parser.add_argument('--loadSizeY', type=int, default=360, help='scale images to this size')\n","# parser.add_argument('--fineSize', type=int, default=256, help='then crop to this size')\n","# parser.add_argument('--epoch', type=int, default=1, help='the starting epoch count')\n","# parser.add_argument('--lr', type=float, default=2e-4, help='initial learning rate')\n","# parser.add_argument('--batchSize', type=int, default=1, help='input batch size')\n","# parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n","# parser.add_argument('--niter', type=int, default=150, help='of iter at starting learning rate')\n","# parser.add_argument('--niter_decay', type=int, default=150, help='of iter to linearly decay learning rate to zero')\n","# parser.add_argument('--save_epoch_freq', type=int, default=1, help='frequency of saving checkpoints at the end '\n","#                                                                    'of epochs')\n","# parser.add_argument('--checkpoints_dir', default='./checkpoints', help='The direction model saved')\n","# parser.add_argument('--load_epoch', type=int, default=1, help='load epoch checkpoint')\n","# parser.add_argument('--gpu', default=0, help='gpu_id')\n","# parser.add_argument('--no_flip', default=True, help='if specified, do not flip the images for data augmentation')\n","\n","# opt = parser.parse_args()\n","class Options:\n","    def __init__(self, **kwargs):\n","        self.__dict__.update(kwargs)\n","\n","args_dict = {\n","    'model': 'train',\n","    'dataroot': 'D:\\Downloads NA C\\MP Project\\ML Proej',\n","    'out_dir': 'D:\\Downloads NA C\\MP Project\\ML Proej',\n","    'loadSizeX': 360,\n","    'loadSizeY': 360,\n","    'fineSize': 256,\n","    'epoch': 1,\n","    'lr': 2e-4,\n","    'batchSize': 1,\n","    'beta1': 0.5,\n","    'niter': 1,\n","    'niter_decay': 0,\n","    'save_epoch_freq': 1,\n","    'checkpoints_dir': 'D:\\Downloads NA C\\MP Project\\ML Proej',\n","    'load_epoch': 1,\n","    'gpu': 0,\n","    'no_flip': True\n","}\n","\n","opt = Options(**args_dict)\n","\n","\n","torch.backends.cudnn.benchmark = True\n","\n","if opt.model == 'train':\n","    netG = DeblurGenerator().apply(weights_init)\n","    netD = DeblurDiscriminator().apply(weights_init)\n","    print( sum(p.numel() for p in netG.parameters()))\n","    print( sum(p.numel() for p in netD.parameters()))\n","    if torch.cuda.is_available():\n","        netG = netG.cuda(opt.gpu)\n","        netD = netD.cuda(opt.gpu)\n","    optim_G = torch.optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n","    optim_D = torch.optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n","\n","    #train(opt, netG, netD, optim_G, optim_D)\n","\n","# import matplotlib.pyplot as plt\n","# a = ReadConcat(opt, transform=image_transform)\n","# img = a[10]['A']\n","# print(type(img))\n","# print(img.shape)\n","# #img = image_recovery(img)\n","# img = img.cpu().float().numpy()\n","# img = (np.transpose(img, (1, 2, 0)) + 1) / 2.0 * 255.0\n","# img = img.astype(np.uint8)\n","# plt.imshow(img)\n","# plt.pause(0)\n","# # print(img.shape)\n","\n","\n","# plt.imshow(image_recovery(img))\n","# plt.pause(0)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T23:33:59.93998Z","iopub.status.busy":"2024-04-09T23:33:59.939676Z","iopub.status.idle":"2024-04-09T23:34:00.749983Z","shell.execute_reply":"2024-04-09T23:34:00.748554Z","shell.execute_reply.started":"2024-04-09T23:33:59.939931Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["E:\\System Temp\\New folder\\ipykernel_11628\\3455324568.py:134: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  net.load_state_dict(torch.load(save_path))\n"]},{"name":"stdout","output_type":"stream","text":["load_netG: 1_net_G.pth\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n","save successfully D:\\Downloads NA C\\MP Project\\ML Proej\\test\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'D:\\\\Downloads NA C\\\\MP Project\\\\ML Proej\\\\test\\\\001\\\\00000000.png'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m      6\u001b[0m     netG \u001b[38;5;241m=\u001b[39m netG\u001b[38;5;241m.\u001b[39mcuda(opt\u001b[38;5;241m.\u001b[39mgpu)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetG\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[28], line 47\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(opt, netG)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# save image\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 47\u001b[0m     \u001b[43msave_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfakeB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave successfully \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(save_path))\n\u001b[0;32m     50\u001b[0m aver_psnr \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m counter\n","Cell \u001b[1;32mIn[25], line 97\u001b[0m, in \u001b[0;36msave_image\u001b[1;34m(image_numpy, image_path)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     image_pil \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(image_numpy)\n\u001b[1;32m---> 97\u001b[0m \u001b[43mimage_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:2456\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2454\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2456\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2458\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2459\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Downloads NA C\\\\MP Project\\\\ML Proej\\\\test\\\\001\\\\00000000.png'"]}],"source":["#uwu\n","import torch\n","netG = DeblurGenerator()\n","load_net(netG, opt.checkpoints_dir, 'G', opt.load_epoch)\n","if torch.cuda.is_available():\n","    netG = netG.cuda(opt.gpu)\n","\n","test(opt, netG)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T23:34:11.910625Z","iopub.status.busy":"2024-04-09T23:34:11.90993Z","iopub.status.idle":"2024-04-10T02:00:22.513617Z","shell.execute_reply":"2024-04-10T02:00:22.512665Z","shell.execute_reply.started":"2024-04-09T23:34:11.910594Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["E:\\System Temp\\New folder\\ipykernel_18580\\2826222385.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  netG.load_state_dict(torch.load('D:\\Downloads NA C\\MP Project\\ML Proej/1_net_G.pth'))\n","E:\\System Temp\\New folder\\ipykernel_18580\\2826222385.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  netD.load_state_dict(torch.load('D:\\Downloads NA C\\MP Project\\ML Proej/1_net_D.pth'))\n","'rm' is not recognized as an internal or external command,\n","operable program or batch file.\n","'rm' is not recognized as an internal or external command,\n","operable program or batch file.\n"]},{"name":"stdout","output_type":"stream","text":["6067459\n","2764737\n","0/1: lossD:0.2655274271965027, lossG:9.105756759643555\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m optim_G \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(netG\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39m(opt\u001b[38;5;241m.\u001b[39mbeta1, \u001b[38;5;241m0.999\u001b[39m))\n\u001b[0;32m     13\u001b[0m optim_D \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(netD\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39m(opt\u001b[38;5;241m.\u001b[39mbeta1, \u001b[38;5;241m0.999\u001b[39m))\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_G\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_D\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[10], line 63\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(opt, netG, netD, optim_G, optim_D)\u001b[0m\n\u001b[0;32m     61\u001b[0m set_requires_grad([netD], \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     62\u001b[0m optim_G\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 63\u001b[0m _, loss_G \u001b[38;5;241m=\u001b[39m \u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfakeB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m loss_G\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     65\u001b[0m optim_G\u001b[38;5;241m.\u001b[39mstep()\n","Cell \u001b[1;32mIn[5], line 175\u001b[0m, in \u001b[0;36mget_loss\u001b[1;34m(tensor, netD, realA, fakeB, realB)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_loss\u001b[39m(tensor, netD, realA, fakeB, realB):\n\u001b[1;32m--> 175\u001b[0m     gan_loss, constant_loss \u001b[38;5;241m=\u001b[39m \u001b[43minit_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     loss_D \u001b[38;5;241m=\u001b[39m gan_loss\u001b[38;5;241m.\u001b[39mget_loss(netD, realA, fakeB, realB)\n\u001b[0;32m    177\u001b[0m     loss_G \u001b[38;5;241m=\u001b[39m gan_loss\u001b[38;5;241m.\u001b[39mget_g_loss(netD, realA, fakeB) \u001b[38;5;241m+\u001b[39m constant_loss\u001b[38;5;241m.\u001b[39mget_loss(fakeB, realB)\n","Cell \u001b[1;32mIn[5], line 167\u001b[0m, in \u001b[0;36minit_loss\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m    164\u001b[0m content_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    166\u001b[0m content_loss \u001b[38;5;241m=\u001b[39m PerceptualLoss()\n\u001b[1;32m--> 167\u001b[0m \u001b[43mcontent_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m disc_loss \u001b[38;5;241m=\u001b[39m DiscLoss()\n\u001b[0;32m    171\u001b[0m disc_loss\u001b[38;5;241m.\u001b[39minitialize(tensor)\n","Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mPerceptualLoss.initialize\u001b[1;34m(self, loss)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontentFunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontentFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[5], line 20\u001b[0m, in \u001b[0;36mPerceptualLoss.contentFunc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontentFunc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Load vgg19 model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     conv_3_3_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m\n\u001b[1;32m---> 20\u001b[0m     cnn \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvgg19\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[0;32m     21\u001b[0m     cnn \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     22\u001b[0m     model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential()\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs\u001b[38;5;241m.\u001b[39mkeys()),\u001b[38;5;250m \u001b[39mseparate_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as positional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    140\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[0;32m    226\u001b[0m     kwargs[weights_param] \u001b[38;5;241m=\u001b[39m default_weights_arg\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\vgg.py:485\u001b[0m, in \u001b[0;36mvgg19\u001b[1;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"VGG-19 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m    :members:\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    483\u001b[0m weights \u001b[38;5;241m=\u001b[39m VGG19_Weights\u001b[38;5;241m.\u001b[39mverify(weights)\n\u001b[1;32m--> 485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\vgg.py:103\u001b[0m, in \u001b[0;36m_vgg\u001b[1;34m(cfg, batch_norm, weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m         _ovewrite_named_param(kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(weights\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m--> 103\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mVGG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(weights\u001b[38;5;241m.\u001b[39mget_state_dict(progress\u001b[38;5;241m=\u001b[39mprogress, check_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\vgg.py:44\u001b[0m, in \u001b[0;36mVGG.__init__\u001b[1;34m(self, features, num_classes, init_weights, dropout)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool2d((\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     45\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     46\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39mdropout),\n\u001b[0;32m     47\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4096\u001b[39m, \u001b[38;5;241m4096\u001b[39m),\n\u001b[0;32m     48\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     49\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39mdropout),\n\u001b[0;32m     50\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4096\u001b[39m, num_classes),\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_weights:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules():\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:104\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:110\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\init.py:460\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[1;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[0;32m    458\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["netG = DeblurGenerator()\n","netD = DeblurDiscriminator()\n","netG.load_state_dict(torch.load('D:\\Downloads NA C\\MP Project\\ML Proej/1_net_G.pth'))\n","netD.load_state_dict(torch.load('D:\\Downloads NA C\\MP Project\\ML Proej/1_net_D.pth'))\n","!rm /kaggle/working/1_net_D.pth\n","!rm /kaggle/working/1_net_G.pth\n","print(sum(p.numel() for p in netG.parameters()))\n","print(sum(p.numel() for p in netD.parameters()))\n","if torch.cuda.is_available():\n","    netG = netG.cuda(opt.gpu)\n","    netD = netD.cuda(opt.gpu)\n","optim_G = torch.optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n","optim_D = torch.optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n","\n","train(opt, netG, netD, optim_G, optim_D)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T02:06:58.400287Z","iopub.status.busy":"2024-04-10T02:06:58.399374Z","iopub.status.idle":"2024-04-10T04:33:04.050096Z","shell.execute_reply":"2024-04-10T04:33:04.049029Z","shell.execute_reply.started":"2024-04-10T02:06:58.400254Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["6067459\n","2764737\n","0/1: lossD:0.6816534996032715, lossG:9.647428512573242\n","50/1: lossD:0.47373539209365845, lossG:9.169012069702148\n","100/1: lossD:0.9380812048912048, lossG:7.084059715270996\n","150/1: lossD:0.6183881163597107, lossG:7.249680995941162\n","200/1: lossD:1.0663646459579468, lossG:8.179444313049316\n","250/1: lossD:0.6810715198516846, lossG:8.777862548828125\n","300/1: lossD:0.7983502149581909, lossG:7.925734519958496\n","350/1: lossD:0.5256534814834595, lossG:7.548954486846924\n","400/1: lossD:0.6454287767410278, lossG:7.77117919921875\n","450/1: lossD:0.6120126843452454, lossG:8.535862922668457\n","500/1: lossD:0.6439659595489502, lossG:11.866963386535645\n","550/1: lossD:0.7053486108779907, lossG:9.540425300598145\n","600/1: lossD:0.2200894057750702, lossG:12.964031219482422\n","650/1: lossD:0.4184153079986572, lossG:9.83285903930664\n","700/1: lossD:0.459089457988739, lossG:10.736726760864258\n","750/1: lossD:1.144104242324829, lossG:10.553278923034668\n","800/1: lossD:0.4371451735496521, lossG:7.4939165115356445\n","850/1: lossD:0.8302547335624695, lossG:8.262500762939453\n","900/1: lossD:0.6720166206359863, lossG:12.380138397216797\n","950/1: lossD:0.7169778347015381, lossG:7.687081813812256\n","1000/1: lossD:1.0749685764312744, lossG:5.568047046661377\n","1050/1: lossD:0.6542492508888245, lossG:8.48314094543457\n","1100/1: lossD:0.2677244246006012, lossG:8.22308349609375\n","1150/1: lossD:1.0210179090499878, lossG:12.09415340423584\n","1200/1: lossD:0.7178797721862793, lossG:9.502239227294922\n","1250/1: lossD:0.37942543625831604, lossG:13.265117645263672\n","1300/1: lossD:0.6175575256347656, lossG:7.447164058685303\n","1350/1: lossD:0.20525804162025452, lossG:10.816496849060059\n","1400/1: lossD:0.4947078227996826, lossG:9.380098342895508\n","1450/1: lossD:0.4750984311103821, lossG:5.869388580322266\n","1500/1: lossD:0.34708356857299805, lossG:11.510371208190918\n","1550/1: lossD:0.6018489599227905, lossG:8.619863510131836\n","1600/1: lossD:0.6023938655853271, lossG:9.510957717895508\n","1650/1: lossD:0.7568358778953552, lossG:8.088623046875\n","1700/1: lossD:0.5102325677871704, lossG:12.224998474121094\n","1750/1: lossD:0.4111670255661011, lossG:12.444915771484375\n","1800/1: lossD:0.8210127353668213, lossG:10.945775985717773\n","1850/1: lossD:0.4724075198173523, lossG:9.47502326965332\n","1900/1: lossD:0.7355169057846069, lossG:5.138601303100586\n","1950/1: lossD:0.4070627689361572, lossG:10.365324974060059\n","2000/1: lossD:0.43299680948257446, lossG:7.162251949310303\n","2050/1: lossD:0.8965945243835449, lossG:10.786550521850586\n","2100/1: lossD:0.3372896909713745, lossG:12.072630882263184\n","2150/1: lossD:0.8761012554168701, lossG:6.819358825683594\n","2200/1: lossD:0.8088763952255249, lossG:8.500860214233398\n","2250/1: lossD:0.4942280352115631, lossG:15.200652122497559\n","2300/1: lossD:0.4846574664115906, lossG:13.85122299194336\n","2350/1: lossD:0.8678438663482666, lossG:7.988674163818359\n","save_netG: 1_net_G.pth\n","save_netD: 1_net_D.pth\n"]}],"source":["netG = DeblurGenerator()\n","netD = DeblurDiscriminator()\n","netG.load_state_dict(torch.load('/kaggle/working/1_net_G.pth'))\n","netD.load_state_dict(torch.load('/kaggle/working/1_net_D.pth'))\n","!rm /kaggle/working/1_net_D.pth\n","!rm /kaggle/working/1_net_G.pth\n","print(sum(p.numel() for p in netG.parameters()))\n","print(sum(p.numel() for p in netD.parameters()))\n","if torch.cuda.is_available():\n","    netG = netG.cuda(opt.gpu)\n","    netD = netD.cuda(opt.gpu)\n","optim_G = torch.optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n","optim_D = torch.optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n","\n","train(opt, netG, netD, optim_G, optim_D)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4754355,"sourceId":8060167,"sourceType":"datasetVersion"},{"datasetId":4757454,"sourceId":8064278,"sourceType":"datasetVersion"},{"datasetId":4767018,"sourceId":8077372,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
